{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b7b6175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "782/782 [==============================] - 7s 8ms/step - loss: 1.8877 - accuracy: 0.3139 - val_loss: 1.7553 - val_accuracy: 0.3733\n",
      "Epoch 2/5\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 1.6823 - accuracy: 0.3974 - val_loss: 1.5914 - val_accuracy: 0.4372\n",
      "Epoch 3/5\n",
      "782/782 [==============================] - 6s 8ms/step - loss: 1.5898 - accuracy: 0.4329 - val_loss: 1.6241 - val_accuracy: 0.4202\n",
      "Epoch 4/5\n",
      "782/782 [==============================] - 6s 8ms/step - loss: 1.5468 - accuracy: 0.4465 - val_loss: 1.5090 - val_accuracy: 0.4652\n",
      "Epoch 5/5\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 1.5035 - accuracy: 0.4627 - val_loss: 1.5727 - val_accuracy: 0.4356\n",
      "- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 1.5727 - accuracy: 0.4356\n",
      "Base Model Results:\n",
      "\n",
      "Test Loss: 1.5727\n",
      "Test Accuracy: 43.56%\n",
      "Time Taken: 30.94 seconds\n",
      "Training with initializer: glorot_uniform\n",
      "\n",
      "Epoch 1/5\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 1.9015 - accuracy: 0.3153\n",
      "Epoch 2/5\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 1.7092 - accuracy: 0.3897\n",
      "Epoch 3/5\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 1.6265 - accuracy: 0.4197\n",
      "Epoch 4/5\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 1.5693 - accuracy: 0.4430\n",
      "Epoch 5/5\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 1.5230 - accuracy: 0.4578\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 1.5504 - accuracy: 0.4451\n",
      "\n",
      "Test Accuracy (using 'glorot_uniform' weight initialization): 44.51%\n",
      "\n",
      "Time Taken: 24.7 seconds\n",
      "\n",
      "- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -\n",
      "Training with initializer: he_normal\n",
      "\n",
      "Epoch 1/5\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 1.8791 - accuracy: 0.3238\n",
      "Epoch 2/5\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 1.6886 - accuracy: 0.3981\n",
      "Epoch 3/5\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 1.6092 - accuracy: 0.4286\n",
      "Epoch 4/5\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 1.5502 - accuracy: 0.4477\n",
      "Epoch 5/5\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 1.5080 - accuracy: 0.4640\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.5811 - accuracy: 0.4315\n",
      "\n",
      "Test Accuracy (using 'he_normal' weight initialization): 43.15%\n",
      "\n",
      "Time Taken: 24.22 seconds\n",
      "\n",
      "- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -\n",
      "Baseline Results Comparison:\n",
      "\n",
      "Accuracy comparison:\n",
      "glorot_uniform: 0.98% accurate than base model\n",
      "he_normal: 1% accurate than base model\n",
      "\n",
      "Time comparison:\n",
      "glorot_uniform: 1.252 seconds faster than base model\n",
      "he_normal: 1.277 seconds faster than base model\n",
      "Epoch 1/5\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 2.0583 - accuracy: 0.2410\n",
      "Epoch 2/5\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.8862 - accuracy: 0.3186\n",
      "Epoch 3/5\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.8113 - accuracy: 0.3483\n",
      "Epoch 4/5\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.7555 - accuracy: 0.3690\n",
      "Epoch 5/5\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 1.7156 - accuracy: 0.3861\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.6382 - accuracy: 0.4092\n",
      "\n",
      "Test Accuracy: 40.92%\n",
      "- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -\n",
      "Baseline Results Comparison:\n",
      "Accuracy: 1.06% faster than base model\n",
      "Epoch 1/5\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 7.3810 - accuracy: 0.3066\n",
      "Epoch 2/5\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 4.7658 - accuracy: 0.3680\n",
      "Epoch 3/5\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 3.4037 - accuracy: 0.3801\n",
      "Epoch 4/5\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 2.6797 - accuracy: 0.3907\n",
      "Epoch 5/5\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 2.2851 - accuracy: 0.4003\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 2.1589 - accuracy: 0.4003\n",
      "\n",
      "Test Accuracy : 40.03%\n",
      "- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -\n",
      "Baseline Results Comparison:\n",
      "Accuracy: 1.09% faster than base model\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, regularizers\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "y_train, y_test = to_categorical(y_train), to_categorical(y_test) # Convert labels to one-hot encoding\n",
    "\n",
    "# BASE MODEL\n",
    "\n",
    "base_model = models.Sequential([\n",
    "    layers.Flatten(input_shape=(32, 32, 3)),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "base_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "st = time.time()\n",
    "base_model_history = base_model.fit(x_train, y_train, epochs=5, batch_size=64, validation_data=(x_test, y_test))\n",
    "sp = time.time()\n",
    "\n",
    "print(\"- -\" * 40)\n",
    "\n",
    "base_test_loss, base_test_acc = base_model.evaluate(x_test, y_test)\n",
    "base_time_taken = round(sp-st, 2)\n",
    "print(f\"Base Model Results:\\n\\nTest Loss: {round(base_test_loss, 4)}\\nTest Accuracy: {round(base_test_acc * 100, 2)}%\\nTime Taken: {base_time_taken} seconds\")\n",
    "\n",
    "# # MODELS WITH KERNEL INITIALIZERS\n",
    "# Xavier & Kaiming Weight Initializers\n",
    "\n",
    "def create_model(initializer=None):\n",
    "    model_with_kernel = models.Sequential([\n",
    "        layers.Flatten(input_shape=(32, 32, 3)),\n",
    "        layers.Dense(256, activation='relu', kernel_initializer=initializer),\n",
    "        layers.Dense(128, activation='relu', kernel_initializer=initializer),\n",
    "        layers.Dense(64, activation='relu', kernel_initializer=initializer),\n",
    "        layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    return model_with_kernel\n",
    "\n",
    "res = []\n",
    "\n",
    "# glorot_uniform - Xavier Weight Initializer, he_normal - Kaiming Weight Initializer\n",
    "weight_initializers = ['glorot_uniform', 'he_normal']\n",
    "\n",
    "for init in weight_initializers:\n",
    "    print(f\"Training with initializer: {init}\\n\")\n",
    "\n",
    "    model = create_model(initializer=init)\n",
    "    model.compile(optimizer='sgd',  loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    wei_st = time.time()\n",
    "    model.fit(x_train, y_train, epochs=5)\n",
    "    wei_sp = time.time()\n",
    "\n",
    "    test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
    "\n",
    "    time_taken = wei_sp - wei_st\n",
    "    res.append((time_taken, test_accuracy))\n",
    "\n",
    "    print(f\"\\nTest Accuracy (using '{init}' weight initialization): {round(test_accuracy * 100, 2)}%\\n\\nTime Taken: {round(time_taken, 2)} seconds\\n\")\n",
    "\n",
    "    print(\"- -\" * 40)\n",
    "\n",
    "# Comparison with baseline results\n",
    "base_glorot_acc = round(base_test_acc / res[0][1], 2)\n",
    "base_glorot_time = round(base_time_taken / res[0][0], 3)\n",
    "base_he_acc = round(base_test_acc / res[1][1])\n",
    "base_he_time = round(base_time_taken / res[1][0], 3)\n",
    "\n",
    "print(f\"Baseline Results Comparison:\\n\\nAccuracy comparison:\\n{weight_initializers[0]}: {base_glorot_acc}% accurate than base model\\n{weight_initializers[1]}: {base_he_acc}% accurate than base model\")\n",
    "print(f\"\\nTime comparison:\\n{weight_initializers[0]}: {base_glorot_time} seconds faster than base model\\n{weight_initializers[1]}: {base_he_time} seconds faster than base model\")\n",
    "\n",
    "\n",
    "# # MODEL WITH DROPOUT LAYER\n",
    "# Dropout Rate - 0.2\n",
    "\n",
    "model_with_dropout = models.Sequential([\n",
    "      layers.Flatten(input_shape=(32, 32, 3)),\n",
    "      layers.Dense(256, activation='relu'),\n",
    "      layers.Dropout(0.2),\n",
    "      layers.Dense(128, activation='relu'),\n",
    "      layers.Dropout(0.2),\n",
    "      layers.Dense(64, activation='relu'),\n",
    "      layers.Dropout(0.2),\n",
    "      layers.Dense(10, activation='softmax')\n",
    "  ])\n",
    "\n",
    "# Load and preprocess CIFAR-10 dataset\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "\n",
    "model_with_dropout.compile(optimizer='sgd', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model_with_dropout.fit(x_train, y_train, epochs=5)\n",
    "\n",
    "dropout_test_loss, dropout_test_accuracy = model_with_dropout.evaluate(x_test, y_test)\n",
    "print(f\"\\nTest Accuracy: {round(dropout_test_accuracy * 100, 4)}%\")\n",
    "\n",
    "print(\"- -\" * 40)\n",
    "\n",
    "# Comparison with baseline results\n",
    "base_dropout_acc = round(base_test_acc / dropout_test_accuracy , 2)\n",
    "\n",
    "print(f\"Baseline Results Comparison:\\nAccuracy: {base_dropout_acc}% faster than base model\")\n",
    "\n",
    "\n",
    "# # MODEL WITH KERNEL REGULARIZER\n",
    "# L2 Kernel Regularizer\n",
    "\n",
    "model_with_reg = models.Sequential([\n",
    "    layers.Flatten(input_shape=(32, 32, 3)),\n",
    "    layers.Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
    "    layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
    "    layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "model_with_reg.compile(optimizer='sgd', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model_with_reg.fit(x_train, y_train, epochs=5)\n",
    "\n",
    "reg_test_loss, reg_test_accuracy = model_with_reg.evaluate(x_test, y_test)\n",
    "print(f\"\\nTest Accuracy : {round(reg_test_accuracy * 100, 4)}%\")\n",
    "\n",
    "print(\"- -\" * 40)\n",
    "\n",
    "# Comparison with baseline results\n",
    "base_reg_acc = round(base_test_acc / reg_test_accuracy , 2)\n",
    "\n",
    "print(f\"Baseline Results Comparison:\\nAccuracy: {base_reg_acc}% faster than base model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dddd61d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
